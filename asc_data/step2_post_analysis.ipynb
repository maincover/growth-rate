{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the reformatting of the mutant data:\n",
    "\n",
    "1 - Averages / standard deviation of growth rates of final OD600 / lag phase / GFP production etc. of technical replicates per experiments.\n",
    "\n",
    "There are always 2 plates per experiment with the exact same content.\n",
    "\n",
    "FOR DATA SET MUT1 - MUT3\n",
    "Plate 1&2 = MUT.0001\n",
    "\n",
    "Plate 3&4 = MUT.0002\n",
    "\n",
    "Plate 5&6 = MUT.0003\n",
    "\n",
    "Plate 7&8 = TS008\n",
    "\n",
    "Plate 9&10 = TS071\n",
    "\n",
    "\n",
    "Plate 11&12 = Blank medium, no cells\n",
    "\n",
    "\n",
    "FOR DATA SET MUT5-MUT7\n",
    "\n",
    "Plate 1&2 = MUT.0005\n",
    "\n",
    "Plate 3&4 = MUT.0006\n",
    "\n",
    "Plate 5&6 = MUT.0007\n",
    "\n",
    "Plate 7&8 = TS008 (control strain 1)\n",
    "\n",
    "Plate 9&10 = TS071 (control strain 2)\n",
    "\n",
    "Plate 11&12 = Blank medium, no cells\n",
    "\n",
    "\n",
    "2 - Averages / standard deviation of growth rates of final OD600 / lag phase / GFP production etc. of the three independent biological replicates executed at three different dates.\n",
    "\n",
    "3 - In the end, I would like to have a matrix per strain with all averages and stand dev's of all the parameters you calculated. Then I can nicely plot the data for each mutant and make a comparison. I will already check the individual data sets today / tomorrow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def getSubFolders(folderPath):\n",
    "    subFolders = []\n",
    "    for root, dirs, files in os.walk(folderPath):\n",
    "        for fn in files:            \n",
    "            if fn.endswith('.csv') and 'stats' in fn:\n",
    "                pth = os.path.join(root, fn)\n",
    "                if root in subFolders:\n",
    "                    continue\n",
    "                subFolders.append(pth)\n",
    "    return subFolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_input = '/home/xsong/Desktop/Ana-promoter-derivetive/Nadine/dataset/Mutant Data - Song/Mutant 1-3 + controls TS008 TS071'\n",
    "lf = getSubFolders(folder_input)\n",
    "folder_list = []\n",
    "plateRule=[]\n",
    "filter_out = ['Plate11','Plate12']\n",
    "import os\n",
    "g = dict()\n",
    "for subFolder in lf:\n",
    "    #print subFolder\n",
    "    plate_name = os.path.split(subFolder)[1]\n",
    "    if plate_name not in g.keys():\n",
    "        g[plate_name] = []\n",
    "    g[plate_name].append(subFolder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 8\n",
      "9 10\n",
      "5 6\n",
      "3 4\n",
      "1 2\n"
     ]
    }
   ],
   "source": [
    "def getEx_dict(l):\n",
    "    experiement_dict =dict()\n",
    "    for s_n in l:\n",
    "        k_bydate = os.path.split(os.path.split(os.path.split(s_n)[0])[0])[1]\n",
    "        if k_bydate not in experiement_dict.keys():\n",
    "            experiement_dict[k_bydate] = []\n",
    "        experiement_dict[k_bydate].append(s_n)\n",
    "    return experiement_dict\n",
    "\n",
    "group_files = dict()\n",
    "for k in g.keys():    \n",
    "    start =  k.index(\"Plate\")    \n",
    "    end =  k.index(\"_stats\")\n",
    "    i =  int(k[start+5:end])        \n",
    "    if i%2 == 0:\n",
    "        #print i\n",
    "        j = i - 1        \n",
    "        for m in g.keys():\n",
    "            start =  m.index(\"Plate\")    \n",
    "            end =  m.index(\"_stats\")\n",
    "            i_m =  int(m[start+5:end])\n",
    "            if i_m == j:\n",
    "                print i_m, i\n",
    "                group_files[(i_m,i)] = g[k]+g[m]\n",
    "\n",
    "for k in group_files.keys():\n",
    "    l = group_files[k]\n",
    "    ex_byDate = getEx_dict(l)\n",
    "    group_files[k] = ex_byDate            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_l(l0,l1):\n",
    "    l0.extend(l1)\n",
    "    return l0\n",
    "\n",
    "def as_list(x):\n",
    "    if type(x) is list:\n",
    "        return x\n",
    "    else:\n",
    "        return [x]\n",
    "    \n",
    "def link_dict(dict1, dict2):    \n",
    "    result = {key: flatten_l(as_list(dict1.get(key, 0)),as_list(dict2.get(key, 0)))\n",
    "              for key in set(dict1) | set(dict2)}\n",
    "    return result\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()   # start with x's keys and values\n",
    "    z.update(y)    # modifies z with y's keys and values & returns None\n",
    "    return z\n",
    "\n",
    "def mean_std_dict(dict0):\n",
    "    import numpy as np\n",
    "    result_m = {key+\"_mean\": np.mean(np.asarray(dict0.get(key,0))) for key in set(dict0)}\n",
    "    result_std = {key+\"_std\": np.std(np.asarray(dict0.get(key,0))) for key in set(dict0)}\n",
    "    return merge_two_dicts(result_m,result_std)\n",
    "\n",
    "def getMeanStd(dic_growth):\n",
    "    if len(dic_growth) > 1:\n",
    "        dic_comb = dic_growth[0]\n",
    "        for i in range(1,len(dic_growth)):                        \n",
    "            dic_comb = link_dict(dic_growth[i], dic_comb)            \n",
    "    else:\n",
    "        print \"only one value array, no mean and std\"\n",
    "        return dic_growth    \n",
    "    result = mean_std_dict(dic_comb)\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGrowthLag(stats_file):\n",
    "    import csv\n",
    "    m_growth = dict()\n",
    "    m_lag = dict()\n",
    "    with open(stats_file) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                #print \"row_0\",row\n",
    "                line_count += 1\n",
    "            else:\n",
    "                #print row\n",
    "                line_count += 1\n",
    "                m_growth[row[0]] = float(row[1])\n",
    "                m_lag[row[0]] = float(row[2])\n",
    "    return m_growth, m_lag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 10)\n",
      "9 Feb 2018\n",
      "1 Feb 2018\n",
      "20 Feb 2018\n",
      "(5, 6)\n",
      "9 Feb 2018\n",
      "1 Feb 2018\n",
      "20 Feb 2018\n",
      "(3, 4)\n",
      "9 Feb 2018\n",
      "1 Feb 2018\n",
      "20 Feb 2018\n",
      "(1, 2)\n",
      "9 Feb 2018\n",
      "1 Feb 2018\n",
      "20 Feb 2018\n",
      "(7, 8)\n",
      "9 Feb 2018\n",
      "1 Feb 2018\n",
      "20 Feb 2018\n"
     ]
    }
   ],
   "source": [
    "growth_rate = dict()\n",
    "lag_phase = dict()\n",
    "\n",
    "for k_group_ex in group_files.keys():\n",
    "    print k_group_ex\n",
    "    growth_rate[k_group_ex] = dict()\n",
    "    lag_phase[k_group_ex] = dict()\n",
    "    \n",
    "    growth_rate[k_group_ex]['mixted_date'] = dict()\n",
    "    lag_phase[k_group_ex]['mixted_date'] = dict()\n",
    "\n",
    "    all_file = []\n",
    "    dic_growth_all = []\n",
    "    dic_lag_all = []\n",
    "    \n",
    "    stats_file_p = group_files[k_group_ex]\n",
    "    for k_date in stats_file_p.keys():\n",
    "        plate_file_date = stats_file_p[k_date] \n",
    "        print k_date        \n",
    "        growth_rate[k_group_ex][k_date]= dict()\n",
    "        lag_phase[k_group_ex][k_date]= dict()        \n",
    "        \n",
    "        dic_growth = []\n",
    "        dic_lag = []\n",
    "        for k_plate in plate_file_date:\n",
    "            #print k_plate            \n",
    "            all_file.append(k_plate)\n",
    "            dic_g, dic_la = getGrowthLag(k_plate)\n",
    "            dic_growth.append(dic_g)\n",
    "            dic_lag.append(dic_la)\n",
    "            \n",
    "            dic_growth_all.append(dic_g)\n",
    "            dic_lag_all.append(dic_la)\n",
    "        \n",
    "        growth_rate[k_group_ex][k_date] = getMeanStd(dic_growth)\n",
    "        lag_phase[k_group_ex][k_date] = getMeanStd(dic_lag)\n",
    "        \n",
    "    growth_rate[k_group_ex]['mixted_date'] = getMeanStd(dic_growth_all)\n",
    "    lag_phase[k_group_ex]['mixted_date'] = getMeanStd(dic_lag_all)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_nicely(l):\n",
    "    import re\n",
    "    \"\"\" Sort the given list in the way that humans expect.\n",
    "    \"\"\"\n",
    "    convert = lambda text: int(text) if text.isdigit() else text\n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ]\n",
    "    l.sort(key=alphanum_key)\n",
    "    return l\n",
    "\n",
    "\n",
    "\n",
    "def get_all_plates(data_in):\n",
    "    all_plates = dict()\n",
    "    for g in sorted(data_in.keys()):\n",
    "        out_file_name = \"plate_\"+str(g[0]) +\"-plate_\"+ str(g[1])\n",
    "        date_all = []\n",
    "        data_all = dict()    \n",
    "        for date in sort_nicely(data_in[g].keys()):        \n",
    "            #print date\n",
    "            data_all[date]=dict()\n",
    "            data = data_in[g][date]            \n",
    "            for k_well in sort_nicely(data.keys()):                 \n",
    "                #if k_well not in data_all.keys():\n",
    "                data_all[date][k_well] = data[k_well]\n",
    "                #else:\n",
    "                    #data_all[date][k_well].extend(as_list(data[k_well]))            \n",
    "        all_plates[out_file_name]=data_all\n",
    "    return all_plates\n",
    "\n",
    "all_plates_growth = get_all_plates(growth_rate)\n",
    "all_plates_lagPhase = get_all_plates(lag_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def writeToFile(f,all_plates,h):\n",
    "    write_head = True\n",
    "    for key in sorted(all_plates.keys()):\n",
    "        if write_head:\n",
    "            f.write(\"%s\"%(key))\n",
    "        else:\n",
    "            f.write(\"%s\\n\"%(key))\n",
    "        for k_date in sort_nicely(all_plates[key].keys()):\n",
    "            string_to_write = \"\\t\"\n",
    "            head = \"\\t\"\n",
    "            for k_well in sort_nicely(all_plates[key][k_date].keys()):\n",
    "                head = head + k_well+h + \"\\t\"\n",
    "                string_to_write = string_to_write + str(all_plates[key][k_date][k_well])+\"\\t\"            \n",
    "            if write_head:\n",
    "                f.write(\"%s\\n\"%(head))\n",
    "                write_head = False            \n",
    "            f.write(\"%s\"%(k_date))\n",
    "            #f.write(\"%s\\n\"%(head))\n",
    "            f.write(\"%s\\n\"%(string_to_write))\n",
    "\n",
    "\n",
    "output_path = os.path.join(folder_input,'growth_rate_lag_phase.csv')\n",
    "with open(output_path, 'w') as f:\n",
    "    writeToFile(f,all_plates_growth,\"_growth_rate\")\n",
    "    f.write(\"\\n\")\n",
    "    writeToFile(f,all_plates_lagPhase,\"_lag_phase\")\n",
    "    \n",
    "            \n",
    "    \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
